{"cells":[{"cell_type":"markdown","metadata":{"editable":false,"papermill":{"duration":0.005852,"end_time":"2023-11-13T05:57:02.734682","exception":false,"start_time":"2023-11-13T05:57:02.72883","status":"completed"},"tags":[]},"source":["# Project Part 3\n","\n","[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/CooperDavis00/CS39AA-Project/blob/main/project-part-3-experiment.ipynb)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sgeinitz/CS39AA-project/blob/main/project_part1.ipynb)"]},{"cell_type":"markdown","metadata":{"editable":false,"papermill":{"duration":0.004893,"end_time":"2023-11-13T05:57:02.745208","exception":false,"start_time":"2023-11-13T05:57:02.740315","status":"completed"},"tags":[]},"source":["## 1. Introduction/Background\n","\n","For project part three  I will be using a couple different song datasets that contain the song title, the artist,  the genre(s) of the song, and I will add some different song attributes to each song. I will also be using my own dataset with my personal spotify data of liked songs, this time also using the same song attributes. This personal dataset will have the same parameters along with a parameter that will say 1 or 0 if I like the song or do not.Initially the liked songs dataset will have a like value of 1 and the other dataset i have not seen will all have like values of 0. Instead of changing those values i am going to add another column called \"like prediction' that will change based on if the song genre and attributes match my own tase in music. All in all, I am using song data to predict if I would like a song based on my own liked songs"]},{"cell_type":"markdown","metadata":{"editable":false,"papermill":{"duration":0.00486,"end_time":"2023-11-13T05:57:02.755316","exception":false,"start_time":"2023-11-13T05:57:02.750456","status":"completed"},"tags":[]},"source":["## 2. Exploratory Data Analysis\n","\n","for part 3 of my project I will be using this dataset: https://www.kaggle.com/datasets/byomokeshsenapati/spotify-song-attributes\n","\n","I wanted to use a larger and more refined dataset for this but in the end it was going to take too much time to generate genres and song attributes for a dataset with 100,000 entries. If the script i wrote to format my own dataset were to be used on the dataset of over 100,000 entries it would take over 9 hours to run through. This dataset has over 10,000 entries and already has genre and song attributes so it will do. \n"]},{"cell_type":"code","execution_count":172,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-12-04T22:48:54.687757Z","iopub.status.busy":"2023-12-04T22:48:54.687420Z","iopub.status.idle":"2023-12-04T22:48:54.693348Z","shell.execute_reply":"2023-12-04T22:48:54.692153Z","shell.execute_reply.started":"2023-12-04T22:48:54.687726Z"},"papermill":{"duration":1.964922,"end_time":"2023-11-13T05:57:04.725382","exception":false,"start_time":"2023-11-13T05:57:02.76046","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.impute import SimpleImputer\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras.utils import to_categorical\n","\n"]},{"cell_type":"markdown","metadata":{"editable":false,"papermill":{"duration":0.005641,"end_time":"2023-11-13T05:57:04.736723","exception":false,"start_time":"2023-11-13T05:57:04.731082","status":"completed"},"tags":[]},"source":["Here is the dataset found from kaggle linked above. Here i read it into a file and format it so the only values displayed are trackName, artistName, and genre. Then I add a like column populated with all zeros since these are the songs i will be predicting and they start with not liked. "]},{"cell_type":"code","execution_count":173,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-12-04T22:48:54.696396Z","iopub.status.busy":"2023-12-04T22:48:54.695023Z","iopub.status.idle":"2023-12-04T22:48:54.852819Z","shell.execute_reply":"2023-12-04T22:48:54.851776Z","shell.execute_reply.started":"2023-12-04T22:48:54.696350Z"},"papermill":{"duration":0.258009,"end_time":"2023-11-13T05:57:05.000089","exception":false,"start_time":"2023-11-13T05:57:04.74208","status":"completed"},"tags":[],"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>trackName</th>\n","      <th>artistName</th>\n","      <th>genre</th>\n","      <th>danceability</th>\n","      <th>energy</th>\n","      <th>loudness</th>\n","      <th>speechiness</th>\n","      <th>acousticness</th>\n","      <th>instrumentalness</th>\n","      <th>liveness</th>\n","      <th>valence</th>\n","      <th>tempo</th>\n","      <th>like</th>\n","      <th>predicted like</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>\"In The Hall Of The Mountain King\" from Peer G...</td>\n","      <td>London Symphony Orchestra</td>\n","      <td>british orchestra</td>\n","      <td>0.475</td>\n","      <td>0.130</td>\n","      <td>-17.719</td>\n","      <td>0.0510</td>\n","      <td>0.9160</td>\n","      <td>0.956000</td>\n","      <td>0.1010</td>\n","      <td>0.122</td>\n","      <td>112.241</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>#BrooklynBloodPop!</td>\n","      <td>SyKo</td>\n","      <td>glitchcore</td>\n","      <td>0.691</td>\n","      <td>0.814</td>\n","      <td>-3.788</td>\n","      <td>0.1170</td>\n","      <td>0.0164</td>\n","      <td>0.000000</td>\n","      <td>0.3660</td>\n","      <td>0.509</td>\n","      <td>132.012</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>$10</td>\n","      <td>Good Morning</td>\n","      <td>experimental pop</td>\n","      <td>0.624</td>\n","      <td>0.596</td>\n","      <td>-9.804</td>\n","      <td>0.0314</td>\n","      <td>0.4750</td>\n","      <td>0.203000</td>\n","      <td>0.1190</td>\n","      <td>0.896</td>\n","      <td>120.969</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>(I Just) Died In Your Arms</td>\n","      <td>Cutting Crew</td>\n","      <td>album rock</td>\n","      <td>0.625</td>\n","      <td>0.726</td>\n","      <td>-11.402</td>\n","      <td>0.0444</td>\n","      <td>0.0158</td>\n","      <td>0.000169</td>\n","      <td>0.0625</td>\n","      <td>0.507</td>\n","      <td>124.945</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>(L)only Child</td>\n","      <td>salem ilese</td>\n","      <td>alt z</td>\n","      <td>0.645</td>\n","      <td>0.611</td>\n","      <td>-5.925</td>\n","      <td>0.1370</td>\n","      <td>0.2900</td>\n","      <td>0.000021</td>\n","      <td>0.2370</td>\n","      <td>0.645</td>\n","      <td>157.475</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                           trackName  \\\n","1  \"In The Hall Of The Mountain King\" from Peer G...   \n","2                                 #BrooklynBloodPop!   \n","3                                                $10   \n","4                         (I Just) Died In Your Arms   \n","5                                      (L)only Child   \n","\n","                  artistName              genre  danceability  energy  \\\n","1  London Symphony Orchestra  british orchestra         0.475   0.130   \n","2                       SyKo         glitchcore         0.691   0.814   \n","3               Good Morning   experimental pop         0.624   0.596   \n","4               Cutting Crew         album rock         0.625   0.726   \n","5                salem ilese              alt z         0.645   0.611   \n","\n","   loudness  speechiness  acousticness  instrumentalness  liveness  valence  \\\n","1   -17.719       0.0510        0.9160          0.956000    0.1010    0.122   \n","2    -3.788       0.1170        0.0164          0.000000    0.3660    0.509   \n","3    -9.804       0.0314        0.4750          0.203000    0.1190    0.896   \n","4   -11.402       0.0444        0.0158          0.000169    0.0625    0.507   \n","5    -5.925       0.1370        0.2900          0.000021    0.2370    0.645   \n","\n","     tempo  like  predicted like  \n","1  112.241     0               0  \n","2  132.012     0               0  \n","3  120.969     0               0  \n","4  124.945     0               0  \n","5  157.475     0               0  "]},"execution_count":173,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('https://raw.githubusercontent.com/CooperDavis00/CS39AA-Project/main/Spotify_Song_Attributes.csv')\n","df = df.drop(['msPlayed','time_signature', 'type', 'id', 'uri', 'track_href', 'analysis_url', 'duration_ms'], axis=1)\n","df['like'] = 0\n","df['predicted like'] = 0\n","df = df.dropna(subset=['genre'])\n","\n","df = df.drop('key', axis=1)\n","df = df.drop('mode', axis=1)\n","\n","df.head()"]},{"cell_type":"markdown","metadata":{"editable":false,"papermill":{"duration":0.005646,"end_time":"2023-11-13T05:57:05.01193","exception":false,"start_time":"2023-11-13T05:57:05.006284","status":"completed"},"tags":[]},"source":["Here is my dataset generated from my own spotify playlist with the same columns and i added a like column populated with ones. \n"]},{"cell_type":"code","execution_count":174,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-12-04T22:48:54.854885Z","iopub.status.busy":"2023-12-04T22:48:54.854179Z","iopub.status.idle":"2023-12-04T22:48:54.928319Z","shell.execute_reply":"2023-12-04T22:48:54.927222Z","shell.execute_reply.started":"2023-12-04T22:48:54.854854Z"},"papermill":{"duration":0.030201,"end_time":"2023-11-13T05:57:05.048447","exception":false,"start_time":"2023-11-13T05:57:05.018246","status":"completed"},"tags":[],"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Track Name</th>\n","      <th>Artist Name(s)</th>\n","      <th>genre</th>\n","      <th>danceability</th>\n","      <th>energy</th>\n","      <th>loudness</th>\n","      <th>speechiness</th>\n","      <th>acousticness</th>\n","      <th>instrumentalness</th>\n","      <th>liveness</th>\n","      <th>valence</th>\n","      <th>tempo</th>\n","      <th>like</th>\n","      <th>predicted like</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Gamesofluck</td>\n","      <td>Parcels</td>\n","      <td>aussietronica, indie soul</td>\n","      <td>0.659</td>\n","      <td>0.757</td>\n","      <td>-5.275</td>\n","      <td>0.0380</td>\n","      <td>0.12800</td>\n","      <td>0.48500</td>\n","      <td>0.0859</td>\n","      <td>0.553</td>\n","      <td>104.997</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>So Much In Love - Armin van Buuren Remix</td>\n","      <td>D.O.D, Armin van Buuren</td>\n","      <td>electro house, house, pop dance, uk dance, dut...</td>\n","      <td>0.672</td>\n","      <td>0.769</td>\n","      <td>-5.887</td>\n","      <td>0.0788</td>\n","      <td>0.04770</td>\n","      <td>0.00488</td>\n","      <td>0.4390</td>\n","      <td>0.390</td>\n","      <td>132.083</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Envious - Rezident Remix</td>\n","      <td>Aluna, Rezident</td>\n","      <td>dance pop, german house, melodic house</td>\n","      <td>0.659</td>\n","      <td>0.710</td>\n","      <td>-7.476</td>\n","      <td>0.0341</td>\n","      <td>0.14300</td>\n","      <td>0.17300</td>\n","      <td>0.0900</td>\n","      <td>0.281</td>\n","      <td>120.020</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Change Your Mind</td>\n","      <td>Interupt</td>\n","      <td>bassline</td>\n","      <td>0.677</td>\n","      <td>0.864</td>\n","      <td>-5.466</td>\n","      <td>0.0689</td>\n","      <td>0.00571</td>\n","      <td>0.00478</td>\n","      <td>0.3560</td>\n","      <td>0.663</td>\n","      <td>128.055</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Isolate</td>\n","      <td>D.O.D</td>\n","      <td>electro house, house, pop dance, uk dance</td>\n","      <td>0.662</td>\n","      <td>0.884</td>\n","      <td>-4.669</td>\n","      <td>0.0500</td>\n","      <td>0.20900</td>\n","      <td>0.16200</td>\n","      <td>0.0980</td>\n","      <td>0.381</td>\n","      <td>126.040</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                 Track Name           Artist Name(s)  \\\n","0                               Gamesofluck                  Parcels   \n","1  So Much In Love - Armin van Buuren Remix  D.O.D, Armin van Buuren   \n","2                  Envious - Rezident Remix          Aluna, Rezident   \n","3                          Change Your Mind                 Interupt   \n","4                                   Isolate                    D.O.D   \n","\n","                                               genre  danceability  energy  \\\n","0                          aussietronica, indie soul         0.659   0.757   \n","1  electro house, house, pop dance, uk dance, dut...         0.672   0.769   \n","2             dance pop, german house, melodic house         0.659   0.710   \n","3                                           bassline         0.677   0.864   \n","4          electro house, house, pop dance, uk dance         0.662   0.884   \n","\n","   loudness  speechiness  acousticness  instrumentalness  liveness  valence  \\\n","0    -5.275       0.0380       0.12800           0.48500    0.0859    0.553   \n","1    -5.887       0.0788       0.04770           0.00488    0.4390    0.390   \n","2    -7.476       0.0341       0.14300           0.17300    0.0900    0.281   \n","3    -5.466       0.0689       0.00571           0.00478    0.3560    0.663   \n","4    -4.669       0.0500       0.20900           0.16200    0.0980    0.381   \n","\n","     tempo  like  predicted like  \n","0  104.997     1               0  \n","1  132.083     1               0  \n","2  120.020     1               0  \n","3  128.055     1               0  \n","4  126.040     1               0  "]},"execution_count":174,"metadata":{},"output_type":"execute_result"}],"source":["df1 = pd.read_csv('https://raw.githubusercontent.com/CooperDavis00/CS39AA-Project/main/liked_w_features.csv')\n","df1['like'] = 1\n","df1['predicted like'] = 0\n","df1 = df1.drop('Track URI', axis = 1)\n","\n","df1 = df1.drop('key', axis=1)\n","df1 = df1.drop('mode', axis=1)\n","\n","\n","df1.head()"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["The column names do not match up so I need to make sure each column matches. "]},{"cell_type":"code","execution_count":175,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-12-04T22:53:06.199820Z","iopub.status.busy":"2023-12-04T22:53:06.199482Z","iopub.status.idle":"2023-12-04T22:53:06.206897Z","shell.execute_reply":"2023-12-04T22:53:06.205872Z","shell.execute_reply.started":"2023-12-04T22:53:06.199795Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Columns in df1: Index(['trackName', 'artistName', 'genre', 'danceability', 'energy',\n","       'loudness', 'speechiness', 'acousticness', 'instrumentalness',\n","       'liveness', 'valence', 'tempo', 'like', 'predicted like'],\n","      dtype='object')\n","Columns in df: Index(['trackName', 'artistName', 'genre', 'danceability', 'energy',\n","       'loudness', 'speechiness', 'acousticness', 'instrumentalness',\n","       'liveness', 'valence', 'tempo', 'like', 'predicted like'],\n","      dtype='object')\n"]}],"source":["# Standardizing column names\n","\n","df1.rename(columns={'Track Name': 'trackName', 'Artist Name(s)': 'artistName', 'Genre': 'genre'}, inplace=True)\n","\n","\n","print(\"Columns in df1:\", df1.columns)\n","print(\"Columns in df:\", df.columns)\n","X_genre = df[['genre']]\n"]},{"cell_type":"markdown","metadata":{"editable":false,"papermill":{"duration":0.005668,"end_time":"2023-11-13T05:57:05.060416","exception":false,"start_time":"2023-11-13T05:57:05.054748","status":"completed"},"tags":[]},"source":["I am counting the different genres and the amount of times each one is displayed. I then display a graph with the top 15 genres and an other category. "]},{"cell_type":"code","execution_count":181,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-12-04T22:54:47.711517Z","iopub.status.busy":"2023-12-04T22:54:47.711146Z","iopub.status.idle":"2023-12-04T22:54:47.818052Z","shell.execute_reply":"2023-12-04T22:54:47.816949Z","shell.execute_reply.started":"2023-12-04T22:54:47.711488Z"},"papermill":{"duration":0.535339,"end_time":"2023-11-13T05:57:05.601645","exception":false,"start_time":"2023-11-13T05:57:05.066306","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["                                  trackName               artistName  \\\n","0                               Gamesofluck                  Parcels   \n","1  So Much In Love - Armin van Buuren Remix  D.O.D, Armin van Buuren   \n","2                  Envious - Rezident Remix          Aluna, Rezident   \n","3                          Change Your Mind                 Interupt   \n","4                                   Isolate                    D.O.D   \n","\n","                                               genre  similar_genres  \n","0                          aussietronica, indie soul           False  \n","1  electro house, house, pop dance, uk dance, dut...           False  \n","2             dance pop, german house, melodic house           False  \n","3                                           bassline           False  \n","4          electro house, house, pop dance, uk dance           False  \n"]}],"source":["# Concatenate datasets\n","combined_df = pd.concat([df1, df], ignore_index=True)\n","\n","combined_df = combined_df.dropna()\n","\n","\n","# Option 1: Binary Classification for Similar Genres\n","combined_df['similar_genres'] = combined_df.groupby('trackName')['genre'].transform(lambda x: set(x) == set(combined_df['genre']))\n","\n","# Create a new DataFrame for genre classification\n","genre_df = combined_df[['trackName', 'artistName', 'genre', 'similar_genres']]\n","\n","# Option 2: Regression for Sound Attributes\n","sound_attributes = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n","\n","# Calculate pairwise Euclidean distances between sound attributes\n","from sklearn.metrics.pairwise import euclidean_distances\n","sound_similarity_matrix = euclidean_distances(combined_df[sound_attributes])\n","\n","# Sum of distances for each row\n","combined_df['sound_similarity'] = sound_similarity_matrix.sum(axis=0)\n","\n","#print(combined_df.head())\n","print(genre_df.head())\n"]},{"cell_type":"code","execution_count":182,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'to_categorical' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m/Users/cooperdavis/Desktop/School/2023-2024/Fall/NLP with Deep Learning/CS39AA-Project/project-part-3.ipynb Cell 13\u001b[0m line \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cooperdavis/Desktop/School/2023-2024/Fall/NLP%20with%20Deep%20Learning/CS39AA-Project/project-part-3.ipynb#X33sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m model_genre\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cooperdavis/Desktop/School/2023-2024/Fall/NLP%20with%20Deep%20Learning/CS39AA-Project/project-part-3.ipynb#X33sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# Convert labels to categorical\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/cooperdavis/Desktop/School/2023-2024/Fall/NLP%20with%20Deep%20Learning/CS39AA-Project/project-part-3.ipynb#X33sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m y_train_genre_encoded \u001b[39m=\u001b[39m to_categorical(y_genre_train, num_classes\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cooperdavis/Desktop/School/2023-2024/Fall/NLP%20with%20Deep%20Learning/CS39AA-Project/project-part-3.ipynb#X33sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m y_val_genre_encoded \u001b[39m=\u001b[39m to_categorical(y_genre_val, num_classes\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cooperdavis/Desktop/School/2023-2024/Fall/NLP%20with%20Deep%20Learning/CS39AA-Project/project-part-3.ipynb#X33sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# Train the model for genre classification\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'to_categorical' is not defined"]}],"source":["# Create a new DataFrame for genre classification\n","genre_df = combined_df[['trackName', 'artistName', 'genre', 'similar_genres']]\n","\n","# Split the genres dataset into training and testing sets without stratification\n","genres_train, genres_val = train_test_split(genre_df, test_size=0.2, random_state=21)\n","\n","# Ensure the labels are integers (convert boolean to integer)\n","genres_train['similar_genres'] = genres_train['similar_genres'].astype(int)\n","genres_val['similar_genres'] = genres_val['similar_genres'].astype(int)\n","\n","# Features and target for genre prediction\n","X_genre_train = genres_train[['trackName', 'artistName', 'genre']]\n","y_genre_train = genres_train['similar_genres']\n","\n","X_genre_val = genres_val[['trackName', 'artistName', 'genre']]\n","y_genre_val = genres_val['similar_genres']\n","\n","# One-hot encode the 'genre' column and convert to integer\n","X_genre_train_encoded = pd.get_dummies(X_genre_train, columns=['genre'], drop_first=True, dtype=int)\n","X_genre_val_encoded = pd.get_dummies(X_genre_val, columns=['genre'], drop_first=True, dtype=int)\n","\n","# Build a model for genre classification\n","model_genre = Sequential()\n","model_genre.add(Dense(128, activation='relu', input_dim=X_genre_train_encoded.shape[1]))\n","model_genre.add(Dropout(0.5))\n","model_genre.add(Dense(64, activation='relu'))\n","model_genre.add(Dense(2, activation='softmax'))  # Use 2 output neurons for binary classification\n","model_genre.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Convert labels to categorical\n","y_train_genre_encoded = to_categorical(y_genre_train, num_classes=2)\n","y_val_genre_encoded = to_categorical(y_genre_val, num_classes=2)\n","\n","# Train the model for genre classification\n","model_genre.fit(X_genre_train_encoded, y_train_genre_encoded, epochs=10, batch_size=32, validation_data=(X_genre_val_encoded, y_val_genre_encoded))\n","\n","# Evaluate the model on the validation set for genre classification\n","accuracy_genre = model_genre.evaluate(X_genre_val_encoded, y_val_genre_encoded)\n","\n","print(\"Accuracy for Genre Classification:\", accuracy_genre)"]},{"cell_type":"code","execution_count":177,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                     trackName    artistName  genre_N/A, N/A, N/A  \\\n","4805  You Dropped A Bomb On Me  The Gap Band                    0   \n","1501      Burning in the Skies   Linkin Park                    0   \n","2581         I Was Never There    The Weeknd                    0   \n","5586         too many feelings          Ruel                    0   \n","4553       Valley of the Hills        Sanjoy                    0   \n","\n","      genre_N/A, N/A, groove room, N/A  genre_N/A, N/A, indie electropop  \\\n","4805                                 0                                 0   \n","1501                                 0                                 0   \n","2581                                 0                                 0   \n","5586                                 0                                 0   \n","4553                                 0                                 0   \n","\n","      genre_N/A, N/A, melodic house  genre_N/A, australian indie  \\\n","4805                              0                            0   \n","1501                              0                            0   \n","2581                              0                            0   \n","5586                              0                            0   \n","4553                              0                            0   \n","\n","      genre_N/A, brostep, glitch hop  genre_N/A, brostep, pop edm, tech house  \\\n","4805                               0                                        0   \n","1501                               0                                        0   \n","2581                               0                                        0   \n","5586                               0                                        0   \n","4553                               0                                        0   \n","\n","      genre_N/A, cape town indie, south african alternative, N/A  ...  \\\n","4805                                                  0           ...   \n","1501                                                  0           ...   \n","2581                                                  0           ...   \n","5586                                                  0           ...   \n","4553                                                  0           ...   \n","\n","      genre_vapor twitch, alternative r&b, melodic house, chillwave, edm, indietronica, industrial pop  \\\n","4805                                                  0                                                  \n","1501                                                  0                                                  \n","2581                                                  0                                                  \n","5586                                                  0                                                  \n","4553                                                  0                                                  \n","\n","      genre_video game music  genre_viral pop  genre_viral rap  \\\n","4805                       0                0                0   \n","1501                       0                0                0   \n","2581                       0                0                0   \n","5586                       0                0                0   \n","4553                       0                0                0   \n","\n","      genre_viral rap, electronica chilena, N/A  genre_virginia indie  \\\n","4805                                          0                     0   \n","1501                                          0                     0   \n","2581                                          0                     0   \n","5586                                          0                     0   \n","4553                                          0                     0   \n","\n","      genre_vocal trance  genre_wave  genre_weirdcore  genre_wonky  \n","4805                   0           0                0            0  \n","1501                   0           0                0            0  \n","2581                   0           0                0            0  \n","5586                   0           0                0            0  \n","4553                   0           0                0            0  \n","\n","[5 rows x 821 columns]\n"]}],"source":["# Split the genres dataset into training and testing sets without stratification\n","genres_train, genres_val = train_test_split(genre_df, test_size=0.2, random_state=21)\n","\n","# Ensure the labels are integers (convert boolean to integer)\n","genres_train['similar_genres'] = genres_train['similar_genres'].astype(int)\n","genres_val['similar_genres'] = genres_val['similar_genres'].astype(int)\n","\n","# Features and target for genre prediction\n","X_genre_train = genres_train[['trackName', 'artistName', 'genre']]\n","y_genre_train = genres_train['similar_genres']\n","\n","X_genre_val = genres_val[['trackName', 'artistName', 'genre']]\n","y_genre_val = genres_val['similar_genres']\n","\n","# One-hot encode the 'genre' column and convert to integer\n","X_genre_train_encoded = pd.get_dummies(X_genre_train, columns=['genre'], drop_first=True, dtype=int)\n","X_genre_val_encoded = pd.get_dummies(X_genre_val, columns=['genre'], drop_first=True, dtype=int)\n","\n","\n","print(X_genre_train_encoded.head())"]},{"cell_type":"code","execution_count":178,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["2023-12-05 02:41:14.172440: W tensorflow/core/framework/op_kernel.cc:1805] OP_REQUIRES failed at cast_op.cc:121 : UNIMPLEMENTED: Cast string to float is not supported\n"]},{"ename":"UnimplementedError","evalue":"Graph execution error:\n\nDetected at node 'sequential_29/Cast' defined at (most recent call last):\n    File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/28/d2b1gshn5v94b_tk47b_x53r0000gn/T/ipykernel_35758/4176374823.py\", line 18, in <cell line: 18>\n      model_genre.fit(X_genre_train, y_train_genre_encoded, epochs=10, batch_size=32, validation_data=(X_genre_val, y_val_genre_encoded))\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/keras/src/engine/training.py\", line 1080, in train_step\n      y_pred = self(x, training=True)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/keras/src/engine/training.py\", line 569, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/keras/src/engine/base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/keras/src/engine/sequential.py\", line 405, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/keras/src/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/keras/src/engine/functional.py\", line 651, in _run_internal_graph\n      y = self._conform_to_reference_input(y, ref_input=x)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/keras/src/engine/functional.py\", line 748, in _conform_to_reference_input\n      tensor = tf.cast(tensor, dtype=ref_input.dtype)\nNode: 'sequential_29/Cast'\nCast string to float is not supported\n\t [[{{node sequential_29/Cast}}]] [Op:__inference_train_function_1030985]","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)","\u001b[1;32m/Users/cooperdavis/Desktop/School/2023-2024/Fall/NLP with Deep Learning/CS39AA-Project/project-part-3.ipynb Cell 14\u001b[0m line \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cooperdavis/Desktop/School/2023-2024/Fall/NLP%20with%20Deep%20Learning/CS39AA-Project/project-part-3.ipynb#X26sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m y_val_genre_encoded \u001b[39m=\u001b[39m label_encoder\u001b[39m.\u001b[39mtransform(y_genre_val)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cooperdavis/Desktop/School/2023-2024/Fall/NLP%20with%20Deep%20Learning/CS39AA-Project/project-part-3.ipynb#X26sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Train the model for genre classification\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/cooperdavis/Desktop/School/2023-2024/Fall/NLP%20with%20Deep%20Learning/CS39AA-Project/project-part-3.ipynb#X26sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m model_genre\u001b[39m.\u001b[39;49mfit(X_genre_train, y_train_genre_encoded, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_genre_val, y_val_genre_encoded))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cooperdavis/Desktop/School/2023-2024/Fall/NLP%20with%20Deep%20Learning/CS39AA-Project/project-part-3.ipynb#X26sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Evaluate the model on the validation set for genre classification\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cooperdavis/Desktop/School/2023-2024/Fall/NLP%20with%20Deep%20Learning/CS39AA-Project/project-part-3.ipynb#X26sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m accuracy_genre \u001b[39m=\u001b[39m model_genre\u001b[39m.\u001b[39mevaluate(X_genre_train, y_val_genre_encoded)\n","File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_29/Cast' defined at (most recent call last):\n    File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/28/d2b1gshn5v94b_tk47b_x53r0000gn/T/ipykernel_35758/4176374823.py\", line 18, in <cell line: 18>\n      model_genre.fit(X_genre_train, y_train_genre_encoded, epochs=10, batch_size=32, validation_data=(X_genre_val, y_val_genre_encoded))\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/keras/src/engine/training.py\", line 1080, in train_step\n      y_pred = self(x, training=True)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/keras/src/engine/training.py\", line 569, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/keras/src/engine/base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/keras/src/engine/sequential.py\", line 405, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/keras/src/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/keras/src/engine/functional.py\", line 651, in _run_internal_graph\n      y = self._conform_to_reference_input(y, ref_input=x)\n    File \"/Users/cooperdavis/Library/Python/3.8/lib/python/site-packages/keras/src/engine/functional.py\", line 748, in _conform_to_reference_input\n      tensor = tf.cast(tensor, dtype=ref_input.dtype)\nNode: 'sequential_29/Cast'\nCast string to float is not supported\n\t [[{{node sequential_29/Cast}}]] [Op:__inference_train_function_1030985]"]}],"source":["from sklearn.preprocessing import LabelEncoder\n","# Build a model for genre classification\n","model_genre = Sequential()\n","model_genre.add(Dense(128, activation='relu', input_dim=X_genre_train.shape[1]))\n","model_genre.add(Dropout(0.5))\n","model_genre.add(Dense(64, activation='relu'))\n","model_genre.add(Dense(1, activation='sigmoid'))\n","\n","# Compile the model for genre classification\n","model_genre.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Use LabelEncoder to convert string labels to numerical values\n","label_encoder = LabelEncoder()\n","y_train_genre_encoded = label_encoder.fit_transform(y_genre_train)\n","y_val_genre_encoded = label_encoder.transform(y_genre_val)\n","\n","# Train the model for genre classification\n","model_genre.fit(X_genre_train, y_train_genre_encoded, epochs=10, batch_size=32, validation_data=(X_genre_val, y_val_genre_encoded))\n","\n","# Evaluate the model on the validation set for genre classification\n","accuracy_genre = model_genre.evaluate(X_genre_train, y_val_genre_encoded)\n","\n","print(\"Accuracy for Genre Classification:\", accuracy_genre)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Build a model for sound similarity regression\n","model_sound = Sequential()\n","model_sound.add(Dense(128, activation='relu', input_dim=X_train_sound.shape[1]))\n","model_sound.add(Dropout(0.5))\n","model_sound.add(Dense(64, activation='relu'))\n","model_sound.add(Dense(1, activation='linear'))\n","\n","# Compile the model for sound similarity regression\n","model_sound.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n","\n","# Train the model for sound similarity regression\n","model_sound.fit(X_train_sound, y_train_sound, epochs=10, batch_size=32, validation_data=(X_val_sound, y_val_sound))\n","\n","# Evaluate the model on the validation set for sound similarity regression\n","accuracy_sound = model_sound.evaluate(X_val_sound, y_val_sound)\n","print(\"Accuracy for Sound Similarity Regression (MAE):\", accuracy_sound)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Experiment with hyperparameter tuning, for example, adjusting dropout rate\n","dropout_rate = 0.2  # Example: Adjust as needed\n","model_combined_tuned = Sequential()\n","model_combined_tuned.add(Dense(128, activation='relu', input_dim=X_train.shape[1]))\n","model_combined_tuned.add(Dropout(dropout_rate))\n","model_combined_tuned.add(Dense(64, activation='relu'))\n","model_combined_tuned.add(Dense(1, activation='sigmoid'))  # Output for genre classification\n","model_combined_tuned.add(Dense(1, activation='linear'))  # Output for sound similarity regression\n","\n","# Compile the tuned model for combined tasks\n","model_combined_tuned.compile(optimizer='adam', loss=['binary_crossentropy', 'mean_squared_error'], metrics=['accuracy', 'mae'])\n","\n","# Train the tuned model for combined tasks\n","model_combined_tuned.fit(X_train, [y_train_genre, y_train_sound], epochs=10, batch_size=32, validation_data=(X_val, [y_val_genre, y_val_sound]))\n","\n","# Evaluate the tuned model on the validation set for genre classification and sound similarity regression\n","accuracy_combined_tuned = model_combined_tuned.evaluate(X_val, [y_val_genre, y_val_sound])\n","print(\"Tuned Model Accuracy (Genre Accuracy, Sound MAE):\", accuracy_combined_tuned)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","228/228 [==============================] - 0s 1ms/step - loss: 0.0875 - accuracy: 0.9926 - val_loss: 0.0356 - val_accuracy: 0.9951\n","Epoch 2/10\n","228/228 [==============================] - 0s 813us/step - loss: 0.0532 - accuracy: 0.9937 - val_loss: 0.0281 - val_accuracy: 0.9951\n","Epoch 3/10\n","228/228 [==============================] - 0s 785us/step - loss: 0.0461 - accuracy: 0.9938 - val_loss: 0.0281 - val_accuracy: 0.9951\n","Epoch 4/10\n","228/228 [==============================] - 0s 784us/step - loss: 0.0377 - accuracy: 0.9944 - val_loss: 0.1052 - val_accuracy: 0.9951\n","Epoch 5/10\n","228/228 [==============================] - 0s 773us/step - loss: 0.0362 - accuracy: 0.9945 - val_loss: 0.0249 - val_accuracy: 0.9951\n","Epoch 6/10\n","228/228 [==============================] - 0s 789us/step - loss: 0.0284 - accuracy: 0.9947 - val_loss: 0.0190 - val_accuracy: 0.9951\n","Epoch 7/10\n","228/228 [==============================] - 0s 816us/step - loss: 0.0258 - accuracy: 0.9945 - val_loss: 0.0178 - val_accuracy: 0.9951\n","Epoch 8/10\n","228/228 [==============================] - 0s 775us/step - loss: 0.0266 - accuracy: 0.9948 - val_loss: 0.0183 - val_accuracy: 0.9951\n","Epoch 9/10\n","228/228 [==============================] - 0s 792us/step - loss: 0.0229 - accuracy: 0.9947 - val_loss: 0.0211 - val_accuracy: 0.9951\n","Epoch 10/10\n","228/228 [==============================] - 0s 949us/step - loss: 0.0220 - accuracy: 0.9948 - val_loss: 0.0225 - val_accuracy: 0.9951\n","57/57 [==============================] - 0s 452us/step - loss: 0.0225 - accuracy: 0.9951\n","Accuracy for Genre Classification: [0.022471996024250984, 0.995063066482544]\n"]}],"source":["\n","# Build a model for genre classification\n","model_genre = Sequential()\n","model_genre.add(Dense(128, activation='relu', input_dim=X_train.shape[1]))\n","model_genre.add(Dropout(0.5))\n","model_genre.add(Dense(64, activation='relu'))\n","model_genre.add(Dense(1, activation='sigmoid'))\n","\n","# Compile the model for genre classification\n","model_genre.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Train the model for genre classification\n","model_genre.fit(X_train, y_train_genre, epochs=10, batch_size=32, validation_data=(X_val, y_val_genre))\n","\n","# Evaluate the model on the validation set for genre classification\n","accuracy_genre = model_genre.evaluate(X_val, y_val_genre)\n","\n","print(\"Accuracy for Genre Classification:\", accuracy_genre)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","228/228 [==============================] - 0s 987us/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n","Epoch 2/10\n","228/228 [==============================] - 0s 1ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n","Epoch 3/10\n","228/228 [==============================] - 0s 761us/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n","Epoch 4/10\n","228/228 [==============================] - 0s 824us/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n","Epoch 5/10\n","228/228 [==============================] - 0s 746us/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n","Epoch 6/10\n","228/228 [==============================] - 0s 736us/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n","Epoch 7/10\n","228/228 [==============================] - 0s 729us/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n","Epoch 8/10\n","228/228 [==============================] - 0s 732us/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n","Epoch 9/10\n","228/228 [==============================] - 0s 761us/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n","Epoch 10/10\n","228/228 [==============================] - 0s 734us/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n","57/57 [==============================] - 0s 428us/step - loss: nan - mae: nan\n","Accuracy for Sound Similarity Regression (MAE): [nan, nan]\n"]}],"source":["# Handling NaN values in input features\n","imputer_X = SimpleImputer(strategy='mean')\n","X_train_imputed = imputer_X.fit_transform(X_train)\n","X_val_imputed = imputer_X.transform(X_val)\n","\n","# Ensure the number of features is the same for X_val_imputed and X_val\n","assert X_val_imputed.shape[1] == X_val.shape[1]\n","\n","# Handling NaN values in the target variable\n","imputer_y = SimpleImputer(strategy='mean')\n","y_train_sound_imputed = imputer_y.fit_transform(y_train_sound.values.reshape(-1, 1)).ravel()\n","y_val_sound_imputed = imputer_y.transform(y_val_sound.values.reshape(-1, 1)).ravel()\n","\n","# Build a model for sound similarity regression\n","model_sound = Sequential()\n","model_sound.add(Dense(128, activation='relu', input_dim=X_train_imputed.shape[1]))\n","model_sound.add(Dropout(0.5))\n","model_sound.add(Dense(64, activation='relu'))\n","model_sound.add(Dense(1, activation='linear'))\n","\n","# Compile the model for sound similarity regression\n","model_sound.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n","\n","# Train the model for sound similarity regression\n","model_sound.fit(X_train_imputed, y_train_sound_imputed, epochs=10, batch_size=32, validation_data=(X_val_imputed, y_val_sound_imputed))\n","\n","# Evaluate the model on the validation set for sound similarity regression\n","accuracy_sound = model_sound.evaluate(X_val_imputed, y_val_sound_imputed)\n","print(\"Accuracy for Sound Similarity Regression (MAE):\", accuracy_sound)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-12-04T22:56:36.663114Z","iopub.status.busy":"2023-12-04T22:56:36.662751Z","iopub.status.idle":"2023-12-04T22:56:42.192640Z","shell.execute_reply":"2023-12-04T22:56:42.191712Z","shell.execute_reply.started":"2023-12-04T22:56:36.663086Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'y_train' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m/Users/cooperdavis/Desktop/School/2023-2024/Fall/NLP with Deep Learning/CS39AA-Project/project-part-3.ipynb Cell 15\u001b[0m line \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cooperdavis/Desktop/School/2023-2024/Fall/NLP%20with%20Deep%20Learning/CS39AA-Project/project-part-3.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cooperdavis/Desktop/School/2023-2024/Fall/NLP%20with%20Deep%20Learning/CS39AA-Project/project-part-3.ipynb#X15sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/cooperdavis/Desktop/School/2023-2024/Fall/NLP%20with%20Deep%20Learning/CS39AA-Project/project-part-3.ipynb#X15sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m model\u001b[39m.\u001b[39mfit(X_train, y_train, epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, validation_data\u001b[39m=\u001b[39m(X_val, y_val))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cooperdavis/Desktop/School/2023-2024/Fall/NLP%20with%20Deep%20Learning/CS39AA-Project/project-part-3.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Evaluate the model on the validation set\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cooperdavis/Desktop/School/2023-2024/Fall/NLP%20with%20Deep%20Learning/CS39AA-Project/project-part-3.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_val, y_val)\n","\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"]}],"source":["model = Sequential()\n","model.add(Dense(128, activation='relu', input_dim=X_train.shape[1]))\n","model.add(Dropout(0.5))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n","\n","# Evaluate the model on the validation set\n","accuracy = model.evaluate(X_val, y_val)\n","accuracy"]},{"cell_type":"markdown","metadata":{"editable":false,"papermill":{"duration":0.006837,"end_time":"2023-11-13T05:57:05.615684","exception":false,"start_time":"2023-11-13T05:57:05.608847","status":"completed"},"tags":[]},"source":["In this cell i am setting up my variable and training with the logisticRegression model. Then I display the shape and initial accuracy. \n"]},{"cell_type":"markdown","metadata":{"editable":false,"papermill":{"duration":0.014654,"end_time":"2023-11-13T05:57:05.881169","exception":false,"start_time":"2023-11-13T05:57:05.866515","status":"completed"},"tags":[]},"source":["testing the accuracy of the model. "]},{"cell_type":"markdown","metadata":{"editable":false,"papermill":{"duration":0.008071,"end_time":"2023-11-13T05:57:06.825425","exception":false,"start_time":"2023-11-13T05:57:06.817354","status":"completed"},"tags":[]},"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30579,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.9"},"papermill":{"default_parameters":{},"duration":8.31423,"end_time":"2023-11-13T05:57:07.455887","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-11-13T05:56:59.141657","version":"2.4.0"}},"nbformat":4,"nbformat_minor":4}
